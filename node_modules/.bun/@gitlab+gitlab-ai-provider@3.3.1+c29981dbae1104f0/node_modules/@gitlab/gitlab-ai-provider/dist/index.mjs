// src/gitlab-anthropic-language-model.ts
import Anthropic from "@anthropic-ai/sdk";

// src/gitlab-direct-access.ts
import { z } from "zod";

// src/gitlab-error.ts
var GitLabError = class _GitLabError extends Error {
  statusCode;
  responseBody;
  cause;
  constructor(options) {
    super(options.message);
    this.name = "GitLabError";
    this.statusCode = options.statusCode;
    this.responseBody = options.responseBody;
    this.cause = options.cause;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, _GitLabError);
    }
  }
  static fromResponse(response, body) {
    return new _GitLabError({
      message: `GitLab API error: ${response.status} ${response.statusText}`,
      statusCode: response.status,
      responseBody: body
    });
  }
  isAuthError() {
    return this.statusCode === 401;
  }
  isRateLimitError() {
    return this.statusCode === 429;
  }
  isForbiddenError() {
    return this.statusCode === 403;
  }
  isServerError() {
    return this.statusCode !== void 0 && this.statusCode >= 500;
  }
};

// src/gitlab-direct-access.ts
var directAccessTokenSchema = z.object({
  headers: z.record(z.string()),
  token: z.string()
});
var DEFAULT_AI_GATEWAY_URL = "https://cloud.gitlab.com";
var GitLabDirectAccessClient = class {
  config;
  fetchFn;
  aiGatewayUrl;
  cachedToken = null;
  tokenExpiresAt = 0;
  constructor(config) {
    this.config = config;
    this.fetchFn = config.fetch ?? fetch;
    this.aiGatewayUrl = config.aiGatewayUrl || process.env["GITLAB_AI_GATEWAY_URL"] || DEFAULT_AI_GATEWAY_URL;
  }
  /**
   * Get a direct access token for the Anthropic proxy.
   * Tokens are cached for 25 minutes (they expire after 30 minutes).
   * @param forceRefresh - If true, ignores the cache and fetches a new token
   */
  async getDirectAccessToken(forceRefresh = false) {
    const now = Date.now();
    if (!forceRefresh && this.cachedToken && this.tokenExpiresAt > now) {
      return this.cachedToken;
    }
    if (forceRefresh) {
      this.invalidateToken();
    }
    const url = `${this.config.instanceUrl}/api/v4/ai/third_party_agents/direct_access`;
    const requestBody = {};
    if (this.config.featureFlags && Object.keys(this.config.featureFlags).length > 0) {
      requestBody.feature_flags = this.config.featureFlags;
    }
    try {
      const response = await this.fetchFn(url, {
        method: "POST",
        headers: {
          ...this.config.getHeaders(),
          "Content-Type": "application/json"
        },
        body: JSON.stringify(requestBody)
      });
      if (!response.ok) {
        const errorText = await response.text();
        if (response.status === 401 && this.config.refreshApiKey && !forceRefresh) {
          try {
            await this.config.refreshApiKey();
            return await this.getDirectAccessToken(true);
          } catch (refreshError) {
            throw new GitLabError({
              message: `Failed to get direct access token: ${response.status} ${response.statusText} - ${errorText}`,
              statusCode: response.status,
              responseBody: errorText
            });
          }
        }
        if (response.status === 403) {
          throw new GitLabError({
            message: `Access denied to GitLab AI features (${this.config.instanceUrl}). This may indicate that: (1) GitLab Duo is not enabled on this instance, (2) Your account does not have access to AI features, or (3) The third-party agents feature is not available. Original error: ${response.status} ${response.statusText} - ${errorText}`,
            statusCode: response.status,
            responseBody: errorText
          });
        }
        throw new GitLabError({
          message: `Failed to get direct access token: ${response.status} ${response.statusText} - ${errorText}`,
          statusCode: response.status,
          responseBody: errorText
        });
      }
      const data = await response.json();
      const token = directAccessTokenSchema.parse(data);
      this.cachedToken = token;
      this.tokenExpiresAt = now + 25 * 60 * 1e3;
      return token;
    } catch (error) {
      if (error instanceof GitLabError) {
        throw error;
      }
      throw new GitLabError({
        message: `Failed to get direct access token: ${error}`,
        cause: error
      });
    }
  }
  /**
   * Get the Anthropic proxy base URL
   */
  getAnthropicProxyUrl() {
    const baseUrl = this.aiGatewayUrl.replace(/\/$/, "");
    return `${baseUrl}/ai/v1/proxy/anthropic/`;
  }
  /**
   * Get the OpenAI proxy base URL
   * Note: The OpenAI SDK expects a base URL like https://api.openai.com/v1
   * and appends paths like /chat/completions. So we need /v1 at the end.
   */
  getOpenAIProxyUrl() {
    const baseUrl = this.aiGatewayUrl.replace(/\/$/, "");
    return `${baseUrl}/ai/v1/proxy/openai/v1`;
  }
  /**
   * Invalidate the cached token
   */
  invalidateToken() {
    this.cachedToken = null;
    this.tokenExpiresAt = 0;
  }
};

// src/gitlab-anthropic-language-model.ts
var GitLabAnthropicLanguageModel = class {
  specificationVersion = "v2";
  modelId;
  supportedUrls = {};
  config;
  directAccessClient;
  anthropicClient = null;
  constructor(modelId, config) {
    this.modelId = modelId;
    this.config = config;
    this.directAccessClient = new GitLabDirectAccessClient({
      instanceUrl: config.instanceUrl,
      getHeaders: config.getHeaders,
      refreshApiKey: config.refreshApiKey,
      fetch: config.fetch,
      featureFlags: config.featureFlags,
      aiGatewayUrl: config.aiGatewayUrl
    });
  }
  get provider() {
    return this.config.provider;
  }
  /**
   * Get or create an Anthropic client with valid credentials
   * @param forceRefresh - If true, forces a token refresh before creating the client
   */
  async getAnthropicClient(forceRefresh = false) {
    const tokenData = await this.directAccessClient.getDirectAccessToken(forceRefresh);
    const { "x-api-key": _removed, ...filteredHeaders } = tokenData.headers;
    this.anthropicClient = new Anthropic({
      apiKey: null,
      authToken: tokenData.token,
      baseURL: this.directAccessClient.getAnthropicProxyUrl(),
      defaultHeaders: filteredHeaders
    });
    return this.anthropicClient;
  }
  /**
   * Check if an error is a token-related authentication error that can be retried
   */
  isTokenError(error) {
    if (error instanceof Anthropic.APIError) {
      if (error.status === 401) {
        return true;
      }
      const message = error.message?.toLowerCase() || "";
      if (message.includes("token") && (message.includes("expired") || message.includes("revoked") || message.includes("invalid"))) {
        return true;
      }
    }
    return false;
  }
  /**
   * Convert AI SDK tools to Anthropic tool format
   */
  convertTools(tools) {
    if (!tools || tools.length === 0) {
      return void 0;
    }
    return tools.filter((tool) => tool.type === "function").map((tool) => {
      const schema = tool.inputSchema;
      return {
        name: tool.name,
        description: tool.description || "",
        input_schema: {
          type: "object",
          properties: schema?.properties || {},
          required: schema?.required || []
        }
      };
    });
  }
  /**
   * Convert AI SDK tool choice to Anthropic format
   */
  convertToolChoice(toolChoice) {
    if (!toolChoice) {
      return void 0;
    }
    switch (toolChoice.type) {
      case "auto":
        return { type: "auto" };
      case "none":
        return void 0;
      case "required":
        return { type: "any" };
      case "tool":
        return { type: "tool", name: toolChoice.toolName };
      default:
        return void 0;
    }
  }
  /**
   * Convert AI SDK prompt to Anthropic messages format
   */
  convertPrompt(prompt) {
    let systemMessage;
    const messages = [];
    for (const message of prompt) {
      if (message.role === "system") {
        systemMessage = message.content;
        continue;
      }
      if (message.role === "user") {
        const content = [];
        for (const part of message.content) {
          if (part.type === "text") {
            content.push({ type: "text", text: part.text });
          } else if (part.type === "file") {
          }
        }
        if (content.length > 0) {
          messages.push({ role: "user", content });
        }
      } else if (message.role === "assistant") {
        const content = [];
        for (const part of message.content) {
          if (part.type === "text") {
            content.push({ type: "text", text: part.text });
          } else if (part.type === "tool-call") {
            content.push({
              type: "tool_use",
              id: part.toolCallId,
              name: part.toolName,
              input: typeof part.input === "string" ? JSON.parse(part.input) : part.input
            });
          }
        }
        if (content.length > 0) {
          messages.push({ role: "assistant", content });
        }
      } else if (message.role === "tool") {
        const content = [];
        for (const part of message.content) {
          if (part.type === "tool-result") {
            let resultContent;
            if (part.output.type === "text") {
              resultContent = part.output.value;
            } else if (part.output.type === "json") {
              resultContent = JSON.stringify(part.output.value);
            } else if (part.output.type === "error-text") {
              resultContent = part.output.value;
            } else if (part.output.type === "error-json") {
              resultContent = JSON.stringify(part.output.value);
            } else {
              resultContent = JSON.stringify(part.output);
            }
            content.push({
              type: "tool_result",
              tool_use_id: part.toolCallId,
              content: resultContent,
              is_error: part.output.type.startsWith("error")
            });
          }
        }
        if (content.length > 0) {
          messages.push({ role: "user", content });
        }
      }
    }
    return { system: systemMessage, messages };
  }
  /**
   * Convert Anthropic finish reason to AI SDK format
   */
  convertFinishReason(stopReason) {
    switch (stopReason) {
      case "end_turn":
        return "stop";
      case "stop_sequence":
        return "stop";
      case "max_tokens":
        return "length";
      case "tool_use":
        return "tool-calls";
      default:
        return "unknown";
    }
  }
  async doGenerate(options) {
    return this.doGenerateWithRetry(options, false);
  }
  async doGenerateWithRetry(options, isRetry) {
    const client = await this.getAnthropicClient(isRetry);
    const { system, messages } = this.convertPrompt(options.prompt);
    const tools = this.convertTools(options.tools);
    const toolChoice = options.toolChoice?.type !== "none" ? this.convertToolChoice(options.toolChoice) : void 0;
    const anthropicModel = this.config.anthropicModel || "claude-sonnet-4-5-20250929";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    try {
      const response = await client.messages.create({
        model: anthropicModel,
        max_tokens: maxTokens,
        system,
        messages,
        tools,
        tool_choice: tools ? toolChoice : void 0,
        temperature: options.temperature,
        top_p: options.topP,
        stop_sequences: options.stopSequences
      });
      const content = [];
      for (const block of response.content) {
        if (block.type === "text") {
          content.push({
            type: "text",
            text: block.text
          });
        } else if (block.type === "tool_use") {
          content.push({
            type: "tool-call",
            toolCallId: block.id,
            toolName: block.name,
            input: JSON.stringify(block.input)
          });
        }
      }
      const usage = {
        inputTokens: response.usage.input_tokens,
        outputTokens: response.usage.output_tokens,
        totalTokens: response.usage.input_tokens + response.usage.output_tokens
      };
      return {
        content,
        finishReason: this.convertFinishReason(response.stop_reason),
        usage,
        warnings: []
      };
    } catch (error) {
      if (!isRetry && this.isTokenError(error)) {
        this.directAccessClient.invalidateToken();
        return this.doGenerateWithRetry(options, true);
      }
      if (error instanceof Anthropic.APIError) {
        throw new GitLabError({
          message: `Anthropic API error: ${error.message}`,
          cause: error
        });
      }
      throw error;
    }
  }
  async doStream(options) {
    return this.doStreamWithRetry(options, false);
  }
  async doStreamWithRetry(options, isRetry) {
    const client = await this.getAnthropicClient(isRetry);
    const { system, messages } = this.convertPrompt(options.prompt);
    const tools = this.convertTools(options.tools);
    const toolChoice = options.toolChoice?.type !== "none" ? this.convertToolChoice(options.toolChoice) : void 0;
    const anthropicModel = this.config.anthropicModel || "claude-sonnet-4-5-20250929";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    const requestBody = {
      model: anthropicModel,
      max_tokens: maxTokens,
      system,
      messages,
      tools,
      tool_choice: tools ? toolChoice : void 0,
      temperature: options.temperature,
      top_p: options.topP,
      stop_sequences: options.stopSequences,
      stream: true
    };
    const self = this;
    const stream = new ReadableStream({
      start: async (controller) => {
        const contentBlocks = {};
        const usage = {
          inputTokens: 0,
          outputTokens: 0,
          totalTokens: 0
        };
        let finishReason = "unknown";
        try {
          const anthropicStream = client.messages.stream(requestBody, {
            signal: options.abortSignal
          });
          controller.enqueue({
            type: "stream-start",
            warnings: []
          });
          await new Promise((resolve2, reject) => {
            anthropicStream.on("streamEvent", (event) => {
              try {
                switch (event.type) {
                  case "message_start":
                    if (event.message.usage) {
                      usage.inputTokens = event.message.usage.input_tokens;
                    }
                    controller.enqueue({
                      type: "response-metadata",
                      id: event.message.id,
                      modelId: event.message.model
                    });
                    break;
                  case "content_block_start":
                    if (event.content_block.type === "text") {
                      const textId = `text-${event.index}`;
                      contentBlocks[event.index] = { type: "text", id: textId };
                      controller.enqueue({
                        type: "text-start",
                        id: textId
                      });
                    } else if (event.content_block.type === "tool_use") {
                      contentBlocks[event.index] = {
                        type: "tool-call",
                        toolCallId: event.content_block.id,
                        toolName: event.content_block.name,
                        input: ""
                      };
                      controller.enqueue({
                        type: "tool-input-start",
                        id: event.content_block.id,
                        toolName: event.content_block.name
                      });
                    }
                    break;
                  case "content_block_delta": {
                    const block = contentBlocks[event.index];
                    if (event.delta.type === "text_delta" && block?.type === "text") {
                      controller.enqueue({
                        type: "text-delta",
                        id: block.id,
                        delta: event.delta.text
                      });
                    } else if (event.delta.type === "input_json_delta" && block?.type === "tool-call") {
                      block.input += event.delta.partial_json;
                      controller.enqueue({
                        type: "tool-input-delta",
                        id: block.toolCallId,
                        delta: event.delta.partial_json
                      });
                    }
                    break;
                  }
                  case "content_block_stop": {
                    const block = contentBlocks[event.index];
                    if (block?.type === "text") {
                      controller.enqueue({
                        type: "text-end",
                        id: block.id
                      });
                    } else if (block?.type === "tool-call") {
                      controller.enqueue({
                        type: "tool-input-end",
                        id: block.toolCallId
                      });
                      controller.enqueue({
                        type: "tool-call",
                        toolCallId: block.toolCallId,
                        toolName: block.toolName,
                        input: block.input === "" ? "{}" : block.input
                      });
                    }
                    delete contentBlocks[event.index];
                    break;
                  }
                  case "message_delta":
                    if (event.usage) {
                      usage.outputTokens = event.usage.output_tokens;
                      usage.totalTokens = (usage.inputTokens || 0) + event.usage.output_tokens;
                    }
                    if (event.delta.stop_reason) {
                      finishReason = self.convertFinishReason(event.delta.stop_reason);
                    }
                    break;
                  case "message_stop": {
                    controller.enqueue({
                      type: "finish",
                      finishReason,
                      usage
                    });
                    break;
                  }
                }
              } catch {
              }
            });
            anthropicStream.on("end", () => {
              resolve2();
            });
            anthropicStream.on("error", (error) => {
              reject(error);
            });
          });
          for (const [, block] of Object.entries(contentBlocks)) {
            if (block.type === "tool-call") {
              controller.enqueue({
                type: "tool-input-end",
                id: block.toolCallId
              });
              controller.enqueue({
                type: "tool-call",
                toolCallId: block.toolCallId,
                toolName: block.toolName,
                input: block.input === "" ? "{}" : block.input
              });
            }
          }
          controller.close();
        } catch (error) {
          for (const [, block] of Object.entries(contentBlocks)) {
            if (block.type === "tool-call") {
              controller.enqueue({
                type: "tool-input-end",
                id: block.toolCallId
              });
              controller.enqueue({
                type: "tool-call",
                toolCallId: block.toolCallId,
                toolName: block.toolName,
                input: block.input === "" ? "{}" : block.input
              });
            }
          }
          if (!isRetry && self.isTokenError(error)) {
            self.directAccessClient.invalidateToken();
            controller.enqueue({
              type: "error",
              error: new GitLabError({
                message: "TOKEN_REFRESH_NEEDED",
                cause: error
              })
            });
            controller.close();
            return;
          }
          if (error instanceof Anthropic.APIError) {
            controller.enqueue({
              type: "error",
              error: new GitLabError({
                message: `Anthropic API error: ${error.message}`,
                cause: error
              })
            });
          } else {
            controller.enqueue({
              type: "error",
              error
            });
          }
          controller.close();
        }
      }
    });
    return {
      stream,
      request: { body: requestBody }
    };
  }
};

// src/gitlab-openai-language-model.ts
import OpenAI from "openai";

// src/model-mappings.ts
var MODEL_MAPPINGS = {
  // Anthropic models
  "duo-chat-opus-4-5": { provider: "anthropic", model: "claude-opus-4-5-20251101" },
  "duo-chat-sonnet-4-5": { provider: "anthropic", model: "claude-sonnet-4-5-20250929" },
  "duo-chat-haiku-4-5": { provider: "anthropic", model: "claude-haiku-4-5-20251001" },
  // OpenAI models - Chat Completions API
  "duo-chat-gpt-5-1": { provider: "openai", model: "gpt-5.1-2025-11-13", openaiApiType: "chat" },
  "duo-chat-gpt-5-2": { provider: "openai", model: "gpt-5.2-2025-12-11", openaiApiType: "chat" },
  "duo-chat-gpt-5-mini": {
    provider: "openai",
    model: "gpt-5-mini-2025-08-07",
    openaiApiType: "chat"
  },
  // OpenAI models - Responses API (Codex models)
  "duo-chat-gpt-5-codex": { provider: "openai", model: "gpt-5-codex", openaiApiType: "responses" },
  "duo-chat-gpt-5-2-codex": {
    provider: "openai",
    model: "gpt-5.2-codex",
    openaiApiType: "responses"
  }
};
function getModelMapping(modelId) {
  return MODEL_MAPPINGS[modelId];
}
function getProviderForModelId(modelId) {
  return MODEL_MAPPINGS[modelId]?.provider;
}
function getValidModelsForProvider(provider) {
  return Object.values(MODEL_MAPPINGS).filter((m) => m.provider === provider).map((m) => m.model);
}
function getAnthropicModelForModelId(modelId) {
  const mapping = MODEL_MAPPINGS[modelId];
  return mapping?.provider === "anthropic" ? mapping.model : void 0;
}
function getOpenAIModelForModelId(modelId) {
  const mapping = MODEL_MAPPINGS[modelId];
  return mapping?.provider === "openai" ? mapping.model : void 0;
}
function getOpenAIApiType(modelId) {
  const mapping = MODEL_MAPPINGS[modelId];
  return mapping?.openaiApiType ?? "chat";
}
function isResponsesApiModel(modelId) {
  return getOpenAIApiType(modelId) === "responses";
}
var MODEL_ID_TO_ANTHROPIC_MODEL = Object.fromEntries(
  Object.entries(MODEL_MAPPINGS).filter(([, v]) => v.provider === "anthropic").map(([k, v]) => [k, v.model])
);

// src/gitlab-openai-language-model.ts
var GitLabOpenAILanguageModel = class {
  specificationVersion = "v2";
  modelId;
  supportedUrls = {};
  config;
  directAccessClient;
  useResponsesApi;
  openaiClient = null;
  constructor(modelId, config) {
    this.modelId = modelId;
    this.config = config;
    this.useResponsesApi = config.useResponsesApi ?? isResponsesApiModel(modelId);
    this.directAccessClient = new GitLabDirectAccessClient({
      instanceUrl: config.instanceUrl,
      getHeaders: config.getHeaders,
      refreshApiKey: config.refreshApiKey,
      fetch: config.fetch,
      featureFlags: config.featureFlags,
      aiGatewayUrl: config.aiGatewayUrl
    });
  }
  get provider() {
    return this.config.provider;
  }
  async getOpenAIClient(forceRefresh = false) {
    const tokenData = await this.directAccessClient.getDirectAccessToken(forceRefresh);
    const { "x-api-key": _removed, ...filteredHeaders } = tokenData.headers;
    this.openaiClient = new OpenAI({
      apiKey: tokenData.token,
      baseURL: this.directAccessClient.getOpenAIProxyUrl(),
      defaultHeaders: filteredHeaders
    });
    return this.openaiClient;
  }
  isTokenError(error) {
    if (error instanceof OpenAI.APIError) {
      if (error.status === 401) {
        return true;
      }
      const message = error.message?.toLowerCase() || "";
      if (message.includes("token") && (message.includes("expired") || message.includes("revoked") || message.includes("invalid"))) {
        return true;
      }
    }
    return false;
  }
  convertTools(tools) {
    if (!tools || tools.length === 0) {
      return void 0;
    }
    return tools.filter((tool) => tool.type === "function").map((tool) => {
      const schema = tool.inputSchema;
      return {
        type: "function",
        function: {
          name: tool.name,
          description: tool.description || "",
          // Ensure the schema has type: 'object' as OpenAI requires it
          parameters: {
            type: "object",
            ...schema
          }
        }
      };
    });
  }
  convertToolChoice(toolChoice) {
    if (!toolChoice) {
      return void 0;
    }
    switch (toolChoice.type) {
      case "auto":
        return "auto";
      case "none":
        return "none";
      case "required":
        return "required";
      case "tool":
        return { type: "function", function: { name: toolChoice.toolName } };
      default:
        return void 0;
    }
  }
  convertPrompt(prompt) {
    const messages = [];
    for (const message of prompt) {
      if (message.role === "system") {
        messages.push({ role: "system", content: message.content });
        continue;
      }
      if (message.role === "user") {
        const textParts = message.content.filter((part) => part.type === "text").map((part) => part.text);
        if (textParts.length > 0) {
          messages.push({ role: "user", content: textParts.join("\n") });
        }
      } else if (message.role === "assistant") {
        const textParts = [];
        const toolCalls = [];
        for (const part of message.content) {
          if (part.type === "text") {
            textParts.push(part.text);
          } else if (part.type === "tool-call") {
            toolCalls.push({
              id: part.toolCallId,
              type: "function",
              function: {
                name: part.toolName,
                arguments: typeof part.input === "string" ? part.input : JSON.stringify(part.input)
              }
            });
          }
        }
        const assistantMessage = {
          role: "assistant",
          content: textParts.length > 0 ? textParts.join("\n") : null
        };
        if (toolCalls.length > 0) {
          assistantMessage.tool_calls = toolCalls;
        }
        messages.push(assistantMessage);
      } else if (message.role === "tool") {
        for (const part of message.content) {
          if (part.type === "tool-result") {
            let resultContent;
            if (part.output.type === "text") {
              resultContent = part.output.value;
            } else if (part.output.type === "json") {
              resultContent = JSON.stringify(part.output.value);
            } else if (part.output.type === "error-text") {
              resultContent = part.output.value;
            } else if (part.output.type === "error-json") {
              resultContent = JSON.stringify(part.output.value);
            } else {
              resultContent = JSON.stringify(part.output);
            }
            messages.push({
              role: "tool",
              tool_call_id: part.toolCallId,
              content: resultContent
            });
          }
        }
      }
    }
    return messages;
  }
  convertFinishReason(finishReason) {
    switch (finishReason) {
      case "stop":
        return "stop";
      case "length":
        return "length";
      case "tool_calls":
        return "tool-calls";
      case "content_filter":
        return "content-filter";
      default:
        return "unknown";
    }
  }
  /**
   * Convert tools to Responses API format
   */
  convertToolsForResponses(tools) {
    if (!tools || tools.length === 0) {
      return void 0;
    }
    return tools.filter((tool) => tool.type === "function").map((tool) => {
      const schema = { ...tool.inputSchema };
      delete schema["$schema"];
      return {
        type: "function",
        name: tool.name,
        description: tool.description || "",
        parameters: schema,
        strict: false
      };
    });
  }
  /**
   * Convert prompt to Responses API input format
   */
  convertPromptForResponses(prompt) {
    const items = [];
    for (const message of prompt) {
      if (message.role === "system") {
        continue;
      }
      if (message.role === "user") {
        const textParts = message.content.filter((part) => part.type === "text").map((part) => part.text);
        if (textParts.length > 0) {
          items.push({
            type: "message",
            role: "user",
            content: textParts.map((text) => ({ type: "input_text", text }))
          });
        }
      } else if (message.role === "assistant") {
        const textParts = [];
        for (const part of message.content) {
          if (part.type === "text") {
            textParts.push(part.text);
          } else if (part.type === "tool-call") {
            items.push({
              type: "function_call",
              call_id: part.toolCallId,
              name: part.toolName,
              arguments: typeof part.input === "string" ? part.input : JSON.stringify(part.input)
            });
          }
        }
        if (textParts.length > 0) {
          items.push({
            type: "message",
            role: "assistant",
            content: [{ type: "output_text", text: textParts.join("\n"), annotations: [] }]
          });
        }
      } else if (message.role === "tool") {
        for (const part of message.content) {
          if (part.type === "tool-result") {
            let resultContent;
            if (part.output.type === "text") {
              resultContent = part.output.value;
            } else if (part.output.type === "json") {
              resultContent = JSON.stringify(part.output.value);
            } else if (part.output.type === "error-text") {
              resultContent = part.output.value;
            } else if (part.output.type === "error-json") {
              resultContent = JSON.stringify(part.output.value);
            } else {
              resultContent = JSON.stringify(part.output);
            }
            items.push({
              type: "function_call_output",
              call_id: part.toolCallId,
              output: resultContent
            });
          }
        }
      }
    }
    return items;
  }
  /**
   * Extract system instructions from prompt
   */
  extractSystemInstructions(prompt) {
    const systemMessages = prompt.filter((m) => m.role === "system").map((m) => m.content).join("\n");
    return systemMessages || void 0;
  }
  /**
   * Convert Responses API status to finish reason
   * Note: Responses API returns 'completed' even when making tool calls,
   * so we need to check the content for tool calls separately.
   */
  convertResponsesStatus(status, hasToolCalls = false) {
    if (hasToolCalls) {
      return "tool-calls";
    }
    switch (status) {
      case "completed":
        return "stop";
      case "incomplete":
        return "length";
      case "cancelled":
        return "stop";
      case "failed":
        return "error";
      default:
        return "unknown";
    }
  }
  async doGenerate(options) {
    if (this.useResponsesApi) {
      return this.doGenerateWithResponsesApi(options, false);
    }
    return this.doGenerateWithChatApi(options, false);
  }
  async doGenerateWithChatApi(options, isRetry) {
    const client = await this.getOpenAIClient(isRetry);
    const messages = this.convertPrompt(options.prompt);
    const tools = this.convertTools(options.tools);
    const toolChoice = options.toolChoice?.type !== "none" ? this.convertToolChoice(options.toolChoice) : void 0;
    const openaiModel = this.config.openaiModel || "gpt-4o";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    try {
      const response = await client.chat.completions.create({
        model: openaiModel,
        max_completion_tokens: maxTokens,
        messages,
        tools,
        tool_choice: tools ? toolChoice : void 0,
        temperature: options.temperature,
        top_p: options.topP,
        stop: options.stopSequences
      });
      const choice = response.choices[0];
      const content = [];
      if (choice?.message.content) {
        content.push({ type: "text", text: choice.message.content });
      }
      if (choice?.message.tool_calls) {
        for (const toolCall of choice.message.tool_calls) {
          if (toolCall.type === "function") {
            content.push({
              type: "tool-call",
              toolCallId: toolCall.id,
              toolName: toolCall.function.name,
              input: toolCall.function.arguments
            });
          }
        }
      }
      const usage = {
        inputTokens: response.usage?.prompt_tokens || 0,
        outputTokens: response.usage?.completion_tokens || 0,
        totalTokens: response.usage?.total_tokens || 0
      };
      return {
        content,
        finishReason: this.convertFinishReason(choice?.finish_reason),
        usage,
        warnings: []
      };
    } catch (error) {
      if (!isRetry && this.isTokenError(error)) {
        this.directAccessClient.invalidateToken();
        return this.doGenerateWithChatApi(options, true);
      }
      if (error instanceof OpenAI.APIError) {
        throw new GitLabError({
          message: `OpenAI API error: ${error.message}`,
          cause: error
        });
      }
      throw error;
    }
  }
  async doGenerateWithResponsesApi(options, isRetry) {
    const client = await this.getOpenAIClient(isRetry);
    const input = this.convertPromptForResponses(options.prompt);
    const tools = this.convertToolsForResponses(options.tools);
    const instructions = this.extractSystemInstructions(options.prompt);
    const openaiModel = this.config.openaiModel || "gpt-5-codex";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    try {
      const response = await client.responses.create({
        model: openaiModel,
        input,
        instructions,
        tools,
        max_output_tokens: maxTokens,
        temperature: options.temperature,
        top_p: options.topP,
        store: false
      });
      const content = [];
      let hasToolCalls = false;
      for (const item of response.output || []) {
        if (item.type === "message" && item.role === "assistant") {
          for (const contentItem of item.content || []) {
            if (contentItem.type === "output_text") {
              content.push({ type: "text", text: contentItem.text });
            }
          }
        } else if (item.type === "function_call") {
          hasToolCalls = true;
          content.push({
            type: "tool-call",
            toolCallId: item.call_id,
            toolName: item.name,
            input: item.arguments
          });
        }
      }
      const usage = {
        inputTokens: response.usage?.input_tokens || 0,
        outputTokens: response.usage?.output_tokens || 0,
        totalTokens: response.usage?.total_tokens || 0
      };
      return {
        content,
        finishReason: this.convertResponsesStatus(response.status, hasToolCalls),
        usage,
        warnings: []
      };
    } catch (error) {
      if (!isRetry && this.isTokenError(error)) {
        this.directAccessClient.invalidateToken();
        return this.doGenerateWithResponsesApi(options, true);
      }
      if (error instanceof OpenAI.APIError) {
        throw new GitLabError({
          message: `OpenAI API error: ${error.message}`,
          cause: error
        });
      }
      throw error;
    }
  }
  async doStream(options) {
    if (this.useResponsesApi) {
      return this.doStreamWithResponsesApi(options, false);
    }
    return this.doStreamWithChatApi(options, false);
  }
  async doStreamWithChatApi(options, isRetry) {
    const client = await this.getOpenAIClient(isRetry);
    const messages = this.convertPrompt(options.prompt);
    const tools = this.convertTools(options.tools);
    const toolChoice = options.toolChoice?.type !== "none" ? this.convertToolChoice(options.toolChoice) : void 0;
    const openaiModel = this.config.openaiModel || "gpt-4o";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    const requestBody = {
      model: openaiModel,
      max_completion_tokens: maxTokens,
      messages,
      tools,
      tool_choice: tools ? toolChoice : void 0,
      temperature: options.temperature,
      top_p: options.topP,
      stop: options.stopSequences,
      stream: true,
      stream_options: { include_usage: true }
    };
    const self = this;
    const stream = new ReadableStream({
      start: async (controller) => {
        const toolCalls = {};
        const usage = {
          inputTokens: 0,
          outputTokens: 0,
          totalTokens: 0
        };
        let finishReason = "unknown";
        let textStarted = false;
        const textId = "text-0";
        try {
          const openaiStream = await client.chat.completions.create({
            ...requestBody,
            stream: true
          });
          controller.enqueue({ type: "stream-start", warnings: [] });
          for await (const chunk of openaiStream) {
            const choice = chunk.choices?.[0];
            if (chunk.id && !textStarted) {
              controller.enqueue({
                type: "response-metadata",
                id: chunk.id,
                modelId: chunk.model
              });
            }
            if (choice?.delta?.content) {
              if (!textStarted) {
                controller.enqueue({ type: "text-start", id: textId });
                textStarted = true;
              }
              controller.enqueue({
                type: "text-delta",
                id: textId,
                delta: choice.delta.content
              });
            }
            if (choice?.delta?.tool_calls) {
              for (const tc of choice.delta.tool_calls) {
                const idx = tc.index;
                if (!toolCalls[idx]) {
                  toolCalls[idx] = {
                    id: tc.id || "",
                    name: tc.function?.name || "",
                    arguments: ""
                  };
                  controller.enqueue({
                    type: "tool-input-start",
                    id: toolCalls[idx].id,
                    toolName: toolCalls[idx].name
                  });
                }
                if (tc.function?.arguments) {
                  toolCalls[idx].arguments += tc.function.arguments;
                  controller.enqueue({
                    type: "tool-input-delta",
                    id: toolCalls[idx].id,
                    delta: tc.function.arguments
                  });
                }
              }
            }
            if (choice?.finish_reason) {
              finishReason = self.convertFinishReason(choice.finish_reason);
            }
            if (chunk.usage) {
              usage.inputTokens = chunk.usage.prompt_tokens || 0;
              usage.outputTokens = chunk.usage.completion_tokens || 0;
              usage.totalTokens = chunk.usage.total_tokens || 0;
            }
          }
          if (textStarted) {
            controller.enqueue({ type: "text-end", id: textId });
          }
          for (const [, tc] of Object.entries(toolCalls)) {
            controller.enqueue({ type: "tool-input-end", id: tc.id });
            controller.enqueue({
              type: "tool-call",
              toolCallId: tc.id,
              toolName: tc.name,
              input: tc.arguments || "{}"
            });
          }
          controller.enqueue({ type: "finish", finishReason, usage });
          controller.close();
        } catch (error) {
          if (!isRetry && self.isTokenError(error)) {
            self.directAccessClient.invalidateToken();
            controller.enqueue({
              type: "error",
              error: new GitLabError({ message: "TOKEN_REFRESH_NEEDED", cause: error })
            });
            controller.close();
            return;
          }
          if (error instanceof OpenAI.APIError) {
            controller.enqueue({
              type: "error",
              error: new GitLabError({
                message: `OpenAI API error: ${error.message}`,
                cause: error
              })
            });
          } else {
            controller.enqueue({ type: "error", error });
          }
          controller.close();
        }
      }
    });
    return { stream, request: { body: requestBody } };
  }
  async doStreamWithResponsesApi(options, isRetry) {
    const client = await this.getOpenAIClient(isRetry);
    const input = this.convertPromptForResponses(options.prompt);
    const tools = this.convertToolsForResponses(options.tools);
    const instructions = this.extractSystemInstructions(options.prompt);
    const openaiModel = this.config.openaiModel || "gpt-5-codex";
    const maxTokens = options.maxOutputTokens || this.config.maxTokens || 8192;
    const requestBody = {
      model: openaiModel,
      input,
      instructions,
      tools,
      max_output_tokens: maxTokens,
      temperature: options.temperature,
      top_p: options.topP,
      store: false,
      stream: true
    };
    const self = this;
    const stream = new ReadableStream({
      start: async (controller) => {
        const toolCalls = {};
        const usage = {
          inputTokens: 0,
          outputTokens: 0,
          totalTokens: 0
        };
        let finishReason = "unknown";
        let textStarted = false;
        const textId = "text-0";
        try {
          const openaiStream = await client.responses.create({
            ...requestBody,
            stream: true
          });
          controller.enqueue({ type: "stream-start", warnings: [] });
          for await (const event of openaiStream) {
            if (event.type === "response.created") {
              controller.enqueue({
                type: "response-metadata",
                id: event.response.id,
                modelId: event.response.model
              });
            } else if (event.type === "response.output_item.added") {
              if (event.item.type === "function_call") {
                const outputIndex = event.output_index;
                const callId = event.item.call_id;
                toolCalls[outputIndex] = {
                  callId,
                  name: event.item.name,
                  arguments: ""
                };
                controller.enqueue({
                  type: "tool-input-start",
                  id: callId,
                  toolName: event.item.name
                });
              }
            } else if (event.type === "response.output_text.delta") {
              if (!textStarted) {
                controller.enqueue({ type: "text-start", id: textId });
                textStarted = true;
              }
              controller.enqueue({
                type: "text-delta",
                id: textId,
                delta: event.delta
              });
            } else if (event.type === "response.function_call_arguments.delta") {
              const outputIndex = event.output_index;
              const tc = toolCalls[outputIndex];
              if (tc) {
                tc.arguments += event.delta;
                controller.enqueue({
                  type: "tool-input-delta",
                  id: tc.callId,
                  delta: event.delta
                });
              }
            } else if (event.type === "response.function_call_arguments.done") {
              const outputIndex = event.output_index;
              const tc = toolCalls[outputIndex];
              if (tc) {
                tc.arguments = event.arguments;
              }
            } else if (event.type === "response.completed") {
              const hasToolCalls2 = Object.keys(toolCalls).length > 0;
              finishReason = self.convertResponsesStatus(event.response.status, hasToolCalls2);
              if (event.response.usage) {
                usage.inputTokens = event.response.usage.input_tokens || 0;
                usage.outputTokens = event.response.usage.output_tokens || 0;
                usage.totalTokens = event.response.usage.total_tokens || 0;
              }
            }
          }
          if (textStarted) {
            controller.enqueue({ type: "text-end", id: textId });
          }
          const hasToolCalls = Object.keys(toolCalls).length > 0;
          if (hasToolCalls && finishReason === "stop") {
            finishReason = "tool-calls";
          }
          for (const tc of Object.values(toolCalls)) {
            controller.enqueue({ type: "tool-input-end", id: tc.callId });
            controller.enqueue({
              type: "tool-call",
              toolCallId: tc.callId,
              toolName: tc.name,
              input: tc.arguments || "{}"
            });
          }
          controller.enqueue({ type: "finish", finishReason, usage });
          controller.close();
        } catch (error) {
          if (!isRetry && self.isTokenError(error)) {
            self.directAccessClient.invalidateToken();
            controller.enqueue({
              type: "error",
              error: new GitLabError({ message: "TOKEN_REFRESH_NEEDED", cause: error })
            });
            controller.close();
            return;
          }
          if (error instanceof OpenAI.APIError) {
            controller.enqueue({
              type: "error",
              error: new GitLabError({
                message: `OpenAI API error: ${error.message}`,
                cause: error
              })
            });
          } else {
            controller.enqueue({ type: "error", error });
          }
          controller.close();
        }
      }
    });
    return { stream, request: { body: requestBody } };
  }
};

// src/gitlab-oauth-types.ts
var BUNDLED_CLIENT_ID = "36f2a70cddeb5a0889d4fd8295c241b7e9848e89cf9e599d0eed2d8e5350fbf5";
var GITLAB_COM_URL = "https://gitlab.com";
var TOKEN_EXPIRY_SKEW_MS = 5 * 60 * 1e3;
var OAUTH_SCOPES = ["api"];

// src/gitlab-oauth-manager.ts
var GitLabOAuthManager = class {
  fetch;
  constructor(fetchImpl = fetch) {
    this.fetch = fetchImpl;
  }
  /**
   * Check if a token is expired
   */
  isTokenExpired(expiresAt) {
    return Date.now() >= expiresAt;
  }
  /**
   * Check if a token needs refresh (within skew window)
   */
  needsRefresh(expiresAt) {
    return Date.now() >= expiresAt - TOKEN_EXPIRY_SKEW_MS;
  }
  /**
   * Refresh tokens if needed
   * Returns the same tokens if refresh is not needed, or new tokens if refreshed
   */
  async refreshIfNeeded(tokens, clientId) {
    if (!this.needsRefresh(tokens.expiresAt)) {
      return tokens;
    }
    if (this.isTokenExpired(tokens.expiresAt)) {
      throw new GitLabError({
        message: "OAuth token has expired and cannot be used"
      });
    }
    return this.exchangeRefreshToken({
      instanceUrl: tokens.instanceUrl,
      refreshToken: tokens.refreshToken,
      clientId
    });
  }
  /**
   * Exchange authorization code for tokens
   * Based on gitlab-vscode-extension createOAuthAccountFromCode
   */
  async exchangeAuthorizationCode(params) {
    const { instanceUrl, code, codeVerifier, clientId, redirectUri } = params;
    const tokenResponse = await this.exchangeToken({
      instanceUrl,
      grantType: "authorization_code",
      code,
      codeVerifier,
      clientId: clientId || this.getClientId(instanceUrl),
      redirectUri
    });
    return this.createTokensFromResponse(tokenResponse, instanceUrl);
  }
  /**
   * Exchange refresh token for new tokens
   * Based on gitlab-vscode-extension TokenExchangeService
   */
  async exchangeRefreshToken(params) {
    const { instanceUrl, refreshToken, clientId } = params;
    const tokenResponse = await this.exchangeToken({
      instanceUrl,
      grantType: "refresh_token",
      refreshToken,
      clientId: clientId || this.getClientId(instanceUrl)
    });
    return this.createTokensFromResponse(tokenResponse, instanceUrl);
  }
  /**
   * Get the OAuth client ID for an instance
   */
  getClientId(instanceUrl) {
    if (instanceUrl === GITLAB_COM_URL) {
      return BUNDLED_CLIENT_ID;
    }
    throw new GitLabError({
      message: `No OAuth client ID configured for instance ${instanceUrl}. Please provide a clientId parameter.`
    });
  }
  /**
   * Exchange token with GitLab OAuth endpoint
   * Based on gitlab-vscode-extension GitLabService.exchangeToken
   */
  async exchangeToken(params) {
    const { instanceUrl, grantType, code, codeVerifier, refreshToken, clientId, redirectUri } = params;
    const body = {
      client_id: clientId,
      grant_type: grantType
    };
    if (grantType === "authorization_code") {
      if (!code || !codeVerifier || !redirectUri) {
        throw new GitLabError({
          message: "Authorization code, code verifier, and redirect URI are required for authorization_code grant"
        });
      }
      body.code = code;
      body.code_verifier = codeVerifier;
      body.redirect_uri = redirectUri;
    } else if (grantType === "refresh_token") {
      if (!refreshToken) {
        throw new GitLabError({
          message: "Refresh token is required for refresh_token grant"
        });
      }
      body.refresh_token = refreshToken;
    }
    const url = `${instanceUrl}/oauth/token`;
    try {
      const response = await this.fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/x-www-form-urlencoded"
        },
        body: new URLSearchParams(body).toString()
      });
      if (!response.ok) {
        const errorText = await response.text();
        throw new GitLabError({
          message: `OAuth token exchange failed: ${response.status} ${response.statusText}`,
          cause: new Error(errorText)
        });
      }
      const data = await response.json();
      return data;
    } catch (error) {
      if (error instanceof GitLabError) {
        throw error;
      }
      throw new GitLabError({
        message: `Failed to exchange OAuth token: ${error instanceof Error ? error.message : String(error)}`,
        cause: error instanceof Error ? error : void 0
      });
    }
  }
  /**
   * Create GitLabOAuthTokens from token response
   */
  createTokensFromResponse(response, instanceUrl) {
    const expiresAt = this.createExpiresTimestamp(response);
    return {
      accessToken: response.access_token,
      refreshToken: response.refresh_token || "",
      expiresAt,
      instanceUrl
    };
  }
  /**
   * Create expiry timestamp from token response
   * Based on gitlab-vscode-extension createExpiresTimestamp
   */
  createExpiresTimestamp(response) {
    const createdAt = response.created_at * 1e3;
    const expiresIn = response.expires_in * 1e3;
    return createdAt + expiresIn;
  }
};

// src/gitlab-provider.ts
import * as fs from "fs";
import * as path from "path";
import * as os from "os";
var VERSION = "0.0.1";
function getOpenCodeAuthPath() {
  const homeDir = os.homedir();
  const xdgDataHome = process.env.XDG_DATA_HOME;
  if (xdgDataHome) {
    return path.join(xdgDataHome, "opencode", "auth.json");
  }
  if (process.platform !== "win32") {
    return path.join(homeDir, ".local", "share", "opencode", "auth.json");
  }
  return path.join(homeDir, ".opencode", "auth.json");
}
async function loadOpenCodeAuth(instanceUrl) {
  try {
    const authPath = getOpenCodeAuthPath();
    if (!fs.existsSync(authPath)) {
      return void 0;
    }
    const authData = JSON.parse(fs.readFileSync(authPath, "utf-8"));
    if (authData.gitlab?.type === "oauth") {
      const gitlabAuth = authData.gitlab;
      if (gitlabAuth.enterpriseUrl === instanceUrl || gitlabAuth.enterpriseUrl === instanceUrl.replace(/\/$/, "")) {
        return gitlabAuth;
      }
    }
    const normalizedUrl = instanceUrl.replace(/\/$/, "");
    const auth = authData[normalizedUrl] || authData[`${normalizedUrl}/`];
    return auth;
  } catch (error) {
    return void 0;
  }
}
async function loadApiKey(options, instanceUrl, clientId) {
  if (options.apiKey) {
    return options.apiKey;
  }
  const auth = await loadOpenCodeAuth(instanceUrl);
  if (auth?.type === "oauth") {
    const oauthManager = new GitLabOAuthManager();
    if (oauthManager.needsRefresh(auth.expires)) {
      try {
        const refreshed = await oauthManager.exchangeRefreshToken({
          instanceUrl,
          refreshToken: auth.refresh,
          clientId
        });
        const authPath = getOpenCodeAuthPath();
        const authData = JSON.parse(fs.readFileSync(authPath, "utf-8"));
        const normalizedUrl = instanceUrl.replace(/\/$/, "");
        authData[normalizedUrl] = {
          type: "oauth",
          refresh: refreshed.refreshToken,
          access: refreshed.accessToken,
          expires: refreshed.expiresAt,
          instanceUrl
        };
        fs.writeFileSync(authPath, JSON.stringify(authData, null, 2));
        return refreshed.accessToken;
      } catch (error) {
        console.warn(
          `Failed to refresh OAuth token: ${error instanceof Error ? error.message : String(error)}`
        );
      }
    } else {
      return auth.access;
    }
  }
  const apiKey = process.env[options.environmentVariableName];
  if (!apiKey) {
    throw new GitLabError({
      message: `${options.description} API key is missing. Pass it as the 'apiKey' parameter, set the ${options.environmentVariableName} environment variable, or authenticate with 'opencode auth login gitlab'.`
    });
  }
  return apiKey;
}
function withUserAgentSuffix(headers, suffix) {
  const userAgent = headers["User-Agent"];
  return {
    ...headers,
    "User-Agent": userAgent ? `${userAgent} ${suffix}` : suffix
  };
}
function createGitLab(options = {}) {
  const instanceUrl = options.instanceUrl ?? "https://gitlab.com";
  const providerName = options.name ?? "gitlab";
  let cachedApiKey;
  let apiKeyPromise;
  const getApiKey = async () => {
    if (cachedApiKey) {
      return cachedApiKey;
    }
    if (apiKeyPromise) {
      return apiKeyPromise;
    }
    apiKeyPromise = loadApiKey(
      {
        apiKey: options.apiKey,
        environmentVariableName: "GITLAB_TOKEN",
        description: "GitLab"
      },
      instanceUrl,
      options.clientId
    );
    cachedApiKey = await apiKeyPromise;
    apiKeyPromise = void 0;
    return cachedApiKey;
  };
  const refreshApiKey = async () => {
    cachedApiKey = void 0;
    apiKeyPromise = void 0;
    cachedApiKey = await getApiKey();
  };
  const getHeaders = () => {
    const apiKey = cachedApiKey || options.apiKey || process.env["GITLAB_TOKEN"] || "";
    if (!apiKey) {
      throw new GitLabError({
        message: "GitLab API key is missing. Pass it as the 'apiKey' parameter, set the GITLAB_TOKEN environment variable, or authenticate with 'opencode auth login gitlab'."
      });
    }
    return withUserAgentSuffix(
      {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
        ...options.headers
      },
      `ai-sdk-gitlab/${VERSION}`
    );
  };
  getApiKey().catch(() => {
  });
  const createAgenticChatModel = (modelId, agenticOptions) => {
    const mapping = getModelMapping(modelId);
    if (!mapping) {
      throw new GitLabError({
        message: `Unknown model ID: ${modelId}. Model must be registered in MODEL_MAPPINGS.`
      });
    }
    if (agenticOptions?.providerModel) {
      const validModels = getValidModelsForProvider(mapping.provider);
      if (!validModels.includes(agenticOptions.providerModel)) {
        throw new GitLabError({
          message: `Invalid providerModel '${agenticOptions.providerModel}' for provider '${mapping.provider}'. Valid models: ${validModels.join(", ")}`
        });
      }
    }
    const featureFlags = {
      DuoAgentPlatformNext: true,
      ...options.featureFlags,
      ...agenticOptions?.featureFlags
    };
    const baseConfig = {
      provider: `${providerName}.agentic`,
      instanceUrl,
      getHeaders,
      refreshApiKey,
      fetch: options.fetch,
      maxTokens: agenticOptions?.maxTokens,
      featureFlags,
      aiGatewayUrl: options.aiGatewayUrl
    };
    if (mapping.provider === "openai") {
      return new GitLabOpenAILanguageModel(modelId, {
        ...baseConfig,
        openaiModel: agenticOptions?.providerModel ?? mapping.model
      });
    }
    return new GitLabAnthropicLanguageModel(modelId, {
      ...baseConfig,
      anthropicModel: agenticOptions?.providerModel ?? mapping.model
    });
  };
  const createDefaultModel = (modelId) => {
    return createAgenticChatModel(modelId);
  };
  const provider = Object.assign((modelId) => createDefaultModel(modelId), {
    specificationVersion: "v2",
    languageModel: createDefaultModel,
    chat: createDefaultModel,
    agenticChat: createAgenticChatModel
  });
  provider.textEmbeddingModel = (modelId) => {
    throw new GitLabError({
      message: `GitLab provider does not support text embedding models. Model ID: ${modelId}`
    });
  };
  provider.imageModel = (modelId) => {
    throw new GitLabError({
      message: `GitLab provider does not support image models. Model ID: ${modelId}`
    });
  };
  return provider;
}
var gitlab = createGitLab();

// src/gitlab-project-detector.ts
import { spawn } from "child_process";
import * as path2 from "path";

// src/gitlab-project-cache.ts
var GitLabProjectCache = class {
  cache = /* @__PURE__ */ new Map();
  defaultTTL;
  /**
   * Create a new project cache
   * @param defaultTTL - Default time-to-live in milliseconds (default: 5 minutes)
   */
  constructor(defaultTTL = 5 * 60 * 1e3) {
    this.defaultTTL = defaultTTL;
  }
  /**
   * Get a cached project by key
   * @param key - Cache key (typically the working directory path)
   * @returns The cached project or null if not found or expired
   */
  get(key) {
    const entry = this.cache.get(key);
    if (!entry) {
      return null;
    }
    if (Date.now() > entry.expiresAt) {
      this.cache.delete(key);
      return null;
    }
    return entry.project;
  }
  /**
   * Store a project in the cache
   * @param key - Cache key (typically the working directory path)
   * @param project - The project to cache
   * @param ttl - Optional custom TTL in milliseconds
   */
  set(key, project, ttl) {
    this.cache.set(key, {
      project,
      expiresAt: Date.now() + (ttl ?? this.defaultTTL)
    });
  }
  /**
   * Check if a key exists in the cache (and is not expired)
   * @param key - Cache key to check
   * @returns true if the key exists and is not expired
   */
  has(key) {
    return this.get(key) !== null;
  }
  /**
   * Remove a specific entry from the cache
   * @param key - Cache key to remove
   */
  delete(key) {
    this.cache.delete(key);
  }
  /**
   * Clear all entries from the cache
   */
  clear() {
    this.cache.clear();
  }
  /**
   * Get the number of entries in the cache (including expired ones)
   */
  get size() {
    return this.cache.size;
  }
  /**
   * Clean up expired entries from the cache
   * This is useful for long-running processes to prevent memory leaks
   */
  cleanup() {
    const now = Date.now();
    for (const [key, entry] of this.cache.entries()) {
      if (now > entry.expiresAt) {
        this.cache.delete(key);
      }
    }
  }
};

// src/gitlab-project-detector.ts
var debugLog = (..._args) => {
};
var GitLabProjectDetector = class {
  config;
  fetchFn;
  cache;
  constructor(config) {
    this.config = {
      gitTimeout: 5e3,
      // 5 seconds default
      ...config
    };
    this.fetchFn = config.fetch ?? fetch;
    this.cache = config.cache ?? new GitLabProjectCache();
  }
  /**
   * Auto-detect GitLab project from git remote in the working directory
   *
   * @param workingDirectory - The directory to check for git remote
   * @param remoteName - The git remote name to use (default: 'origin')
   * @returns The detected project or null if detection fails
   */
  async detectProject(workingDirectory, remoteName = "origin") {
    const cacheKey = path2.resolve(workingDirectory);
    const cached = this.cache.get(cacheKey);
    if (cached) {
      return cached;
    }
    try {
      debugLog(`[GitLabProjectDetector] Getting git remote URL from: ${workingDirectory}`);
      const remoteUrl = await this.getGitRemoteUrl(workingDirectory, remoteName);
      if (!remoteUrl) {
        debugLog(`[GitLabProjectDetector] No git remote URL found`);
        return null;
      }
      debugLog(`[GitLabProjectDetector] Git remote URL: ${remoteUrl}`);
      debugLog(
        `[GitLabProjectDetector] Parsing project path from URL (instance: ${this.config.instanceUrl})`
      );
      const projectPath = this.parseGitRemoteUrl(remoteUrl, this.config.instanceUrl);
      if (!projectPath) {
        debugLog(
          `[GitLabProjectDetector] Could not parse project path from URL (remote doesn't match instance)`
        );
        return null;
      }
      debugLog(`[GitLabProjectDetector] Parsed project path: ${projectPath}`);
      debugLog(`[GitLabProjectDetector] Fetching project from GitLab API: ${projectPath}`);
      const project = await this.getProjectByPath(projectPath);
      debugLog(`[GitLabProjectDetector] \u2713 Project fetched successfully:`, project);
      this.cache.set(cacheKey, project);
      return project;
    } catch (error) {
      if (error instanceof GitLabError) {
        debugLog(`[GitLabProjectDetector] GitLab API error:`, error.message || error);
        return null;
      }
      debugLog(`[GitLabProjectDetector] Unexpected error:`, error);
      console.warn(`Failed to auto-detect GitLab project: ${error}`);
      return null;
    }
  }
  /**
   * Parse a git remote URL to extract the project path
   *
   * Supports:
   * - SSH: git@gitlab.com:namespace/project.git
   * - HTTPS: https://gitlab.com/namespace/project.git
   * - HTTP: http://gitlab.local/namespace/project.git
   * - Custom domains and ports
   *
   * @param remoteUrl - The git remote URL
   * @param instanceUrl - The GitLab instance URL to match against
   * @returns The project path (e.g., "namespace/project") or null if parsing fails
   */
  parseGitRemoteUrl(remoteUrl, instanceUrl) {
    try {
      const instanceHost = new URL(instanceUrl).hostname;
      const sshMatch = remoteUrl.match(/^git@([^:]+):(.+?)(?:\.git)?$/);
      if (sshMatch) {
        const [, host, pathPart] = sshMatch;
        const hostWithoutPort = host.split(":")[0];
        if (hostWithoutPort === instanceHost) {
          const cleanPath = pathPart.replace(/^\d+\//, "");
          return cleanPath.endsWith(".git") ? cleanPath.slice(0, -4) : cleanPath;
        }
      }
      const httpsMatch = remoteUrl.match(/^(https?):\/\/([^/]+)\/(.+?)(?:\.git)?$/);
      if (httpsMatch) {
        const [, , hostWithPort, pathPart] = httpsMatch;
        const host = hostWithPort.split(":")[0];
        if (host === instanceHost) {
          return pathPart.endsWith(".git") ? pathPart.slice(0, -4) : pathPart;
        }
      }
      return null;
    } catch (error) {
      return null;
    }
  }
  /**
   * Get the git remote URL from a working directory
   *
   * @param workingDirectory - The directory to check
   * @param remoteName - The git remote name (default: 'origin')
   * @returns The remote URL or null if not found
   */
  async getGitRemoteUrl(workingDirectory, remoteName = "origin") {
    return new Promise((resolve2) => {
      const child = spawn("git", ["config", "--get", `remote.${remoteName}.url`], {
        cwd: workingDirectory,
        timeout: this.config.gitTimeout
      });
      let stdout = "";
      let _stderr = "";
      child.stdout?.on("data", (data) => {
        stdout += data.toString();
      });
      child.stderr?.on("data", (data) => {
        _stderr += data.toString();
      });
      child.on("close", (exitCode) => {
        if (exitCode === 0 && stdout.trim()) {
          resolve2(stdout.trim());
        } else {
          resolve2(null);
        }
      });
      child.on("error", () => {
        resolve2(null);
      });
    });
  }
  /**
   * Fetch project details from GitLab API by project path
   *
   * @param projectPath - The project path (e.g., "namespace/project")
   * @returns The project details
   * @throws GitLabError if the API call fails
   */
  async getProjectByPath(projectPath) {
    const encodedPath = encodeURIComponent(projectPath);
    const url = `${this.config.instanceUrl}/api/v4/projects/${encodedPath}`;
    try {
      const response = await this.fetchFn(url, {
        method: "GET",
        headers: this.config.getHeaders()
      });
      if (!response.ok) {
        throw new GitLabError({
          message: `Failed to fetch project '${projectPath}': ${response.status} ${response.statusText}`
        });
      }
      const data = await response.json();
      return {
        id: data.id,
        path: data.path,
        pathWithNamespace: data.path_with_namespace,
        name: data.name,
        namespaceId: data.namespace?.id
      };
    } catch (error) {
      if (error instanceof GitLabError) {
        throw error;
      }
      throw new GitLabError({
        message: `Failed to fetch project '${projectPath}': ${error}`,
        cause: error
      });
    }
  }
  /**
   * Clear the project cache
   */
  clearCache() {
    this.cache.clear();
  }
  /**
   * Get the cache instance (useful for testing)
   */
  getCache() {
    return this.cache;
  }
};
export {
  BUNDLED_CLIENT_ID,
  DEFAULT_AI_GATEWAY_URL,
  GITLAB_COM_URL,
  GitLabAnthropicLanguageModel,
  GitLabDirectAccessClient,
  GitLabError,
  GitLabOAuthManager,
  GitLabOpenAILanguageModel,
  GitLabProjectCache,
  GitLabProjectDetector,
  MODEL_ID_TO_ANTHROPIC_MODEL,
  MODEL_MAPPINGS,
  OAUTH_SCOPES,
  TOKEN_EXPIRY_SKEW_MS,
  createGitLab,
  getAnthropicModelForModelId,
  getModelMapping,
  getOpenAIApiType,
  getOpenAIModelForModelId,
  getProviderForModelId,
  getValidModelsForProvider,
  gitlab,
  isResponsesApiModel
};
//# sourceMappingURL=index.mjs.map